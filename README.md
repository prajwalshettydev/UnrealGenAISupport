# Unreal Engine Generative AI Support Plugin

> [!WARNING]  
> This plugin is currently under development and not ready for production use.

This project aims to build a long-term support (LTS) plugin for various cutting-edge LLM/GenAI models & foster a
community around it. It currently includes OpenAI's GPT4o & GPT4o-mini for Unreal Engine 5.1 or higher, with plans to add Claude
Sonnet 3.5, real-time APIs, Deepseek, Gemini, & Grok 2 APIs soon. Will only focus on the APIs that can be useful for
game development and interactive experiences. Any suggestions
and contributions are welcome. Currently working on OpenAI API support with real-time chat/audio completions.

## Current Progress:

- OpenAI API Support:
    - OpenAI Chat API âœ…
        - `gpt-4o` Model âœ…
        - `gpt-4o-mini` Model âœ…
        - `o1-mini` Model ðŸš§
        - `o1` Model ðŸš§
    - OpenAI DALL-E API ðŸ› ï¸
    - OpenAI Vision API ðŸš§
    - OpenAI Realtime API ðŸ› ï¸
    - OpenAI Structured Outputs âœ…
    - OpenAI Text-To-Speech API ðŸš§
    - OpenAI Whisper API ðŸš§
- Anthropic Claude API Support:
    - Claude Chat API ðŸš§
        - `claude-3-5-sonnet-latest` Model ðŸš§
        - `claude-3-5-haiku-latest` Model ðŸš§
        - `claude-3-opus-latest` Model ðŸš§
    - Claude Vision API ðŸš§
- XAI (Grok) API Support:
    - XAI Chat Completions API ðŸš§
        - `grok-beta` Model ðŸš§
        - `grok-beta` Streaming API ðŸš§
    - XAI Image API ðŸš§
- Google Gemini API Support:
    - Gemini Chat API ðŸš§
        - `gemini-2.0-flash-exp` Model ðŸš§
        - `gemini-1.5-flash` Model ðŸš§
        - `gemini-1.5-flash-8b` Model ðŸš§
    - Gemini Multi-Modal API ðŸš§
- Meta AI API Support:
    - Llama Chat API ðŸš§
        - `llama3.3-70b` Model ðŸš§
        - `llama3.1-8b` Model ðŸš§
    - Multi-Modal Vision API ðŸš§
        - `llama3.2-90b-vision` Model ðŸš§
    - Local Llama API ðŸš§
- Deepseek API Support:
    - Deepseek Chat API ðŸš§
        - `deepseek-chat` (DeepSeek-V3) Model ðŸš§
- API Key Management 
    - Cross-Platform Secure Key Storage âœ…
    - Encrypted Key Storage ðŸ› ï¸
    - Cross Platform Testing ðŸš§
    - Build System Integration ðŸ› ï¸
    - Keys in Build Configuration ðŸ› ï¸
- Unreal Engine Integration
    - Blueprint Support ðŸ› ï¸
    - C++ Support ðŸ› ï¸
    - C++ Latent Functions For Blueprints ðŸ› ï¸
    - Packaged Build Support ðŸ› ï¸
- Plugin Documentation ðŸ› ï¸
- Plugin Examples ðŸš§
- Version Control Support
    - Perforce Support ðŸš§
    - Git Submodule Support âœ… 
- LTS Branching ðŸš§
    - Stable Branch with Bug Fixes ðŸš§
    - Dedicated Contributor for LTS ðŸš§
- Lightweight Plugin (In Builds) 
    - No External Dependencies âœ…
    - Build Flags to enable/disable APIs ðŸš§
    - Submodules per API Organization ðŸš§
- Testing 
    - Automated Testing ðŸš§
    - Build Testing ðŸš§
    - Different Platforms ðŸš§
    - Different Engine Versions ðŸš§

## Quick Links:

- [OpenAI API Documentation](https://platform.openai.com/docs/api-reference)
- [Anthropic API Documentation](https://docs.anthropic.com/en/docs/about-claude/models)
- [XAI API Documentation](https://docs.x.ai/api)
- [Google Gemini API Documentation](https://ai.google.dev/gemini-api/docs/models/gemini)
- [Meta AI API Documentation](https://docs.llama-api.com/quickstart#available-models)
- [Deepseek API Documentation](https://api-docs.deepseek.com/)

## Setting API Key:

### For Editor:

Set the environment variable `PS_OPENAIAPIKEY` to your API key.
In windows you can use:

```cmd
setx PS_OPENAIAPIKEY "your api key"
```

In Linux/MacOS you can use:

```bash
export PS_OPENAIAPIKEY="your api key"
```

### For Packaged Builds:

Still in development..

## Adding the plugin to your project:

### With Git:

1. Add the Plugin Repository as a Submodule in your project's repository.

   ```cmd
   git submodule add https://github.com/prajwalshettydev/UnrealGenAISupport Plugins/GenerativeAISupport
   ```

2. Regenerate Project Files:
   Right-click your .uproject file and select Generate Visual Studio project files.
3. Enable the Plugin in Unreal Editor:
   Open your project in Unreal Editor. Go to Edit > Plugins. Search for the Plugin in the list and enable it.
4. For Unreal C++ Projects, include the Plugin's module in your project's Build.cs file:

   ```cpp
   PrivateDependencyModuleNames.AddRange(new string[] { "GenerativeAISupport" });
   ```

### With Perforce:

Still in development..

## Fetching the Latest Plugin Changes:

### With Git:

you can pull the latest changes with:

```cmd
cd Plugins/GenerativeAISupport
git pull origin main
```

Or update all submodules in the project:

```cmd
git submodule update --recursive --remote
```

### With Perforce:

Still in development..

## Usage:

### OpenAI:

Function `GetGenerativeAIApiKey` by default responds with OpenAI API key, that you have securely set in the local
environment variable

1. Chat:

   C++ Example:
    ```cpp
    void SomeDebugSubsystem::CallGPT(const FString& Prompt, 
        const TFunction<void(const FString&, const FString&, bool)>& Callback)
    {
        FGenChatSettings ChatSettings;
        ChatSettings.Model = TEXT("gpt-4o-mini");
        ChatSettings.MaxTokens = 500;
        ChatSettings.Messages.Add(FGenChatMessage{ TEXT("system"), Prompt });
    
        FOnChatCompletionResponse OnComplete = FOnChatCompletionResponse::CreateLambda(
            [Callback](const FString& Response, const FString& ErrorMessage, bool bSuccess)
        {
            Callback(Response, ErrorMessage, bSuccess);
        });
    
        UGenOAIChat::SendChatRequest(ChatSettings, OnComplete);
    }
    ```

   Blueprint Example:

    <img src="Docs/BpExampleOAIChat.png" width="782"/>
2. Structured Outputs:
   C++ Example 1:
   Sending a custom schema json directly to function call
   ```cpp
   FString MySchemaJson = R"({
   "type": "object",
   "properties": {
       "count": {
           "type": "integer",
           "description": "The total number of users."
       },
       "users": {
           "type": "array",
           "items": {
               "type": "object",
               "properties": {
                   "name": { "type": "string", "description": "The user's name." },
                   "heading_to": { "type": "string", "description": "The user's destination." }
               },
               "required": ["name", "role", "age", "heading_to"]
           }
       }
   },
   "required": ["count", "users"]
   })";
   
   UGenAISchemaService::RequestStructuredOutput(
       TEXT("Generate a list of users and their details"),
       MySchemaJson,
       [](const FString& Response, const FString& Error, bool Success) {
          if (Success)
          {
              UE_LOG(LogTemp, Log, TEXT("Structured Output: %s"), *Response);
          }
          else
          {
              UE_LOG(LogTemp, Error, TEXT("Error: %s"), *Error);
          }
       }
   );
   ```
   C++ Example 2:
   Sending a custom schema json from a file
   ```cpp
   #include "Misc/FileHelper.h"
   #include "Misc/Paths.h"
   FString SchemaFilePath = FPaths::Combine(
       FPaths::ProjectDir(),
       TEXT("Source/:ProjectName/Public/AIPrompts/SomeSchema.json")
   );
   
   FString MySchemaJson;
   if (FFileHelper::LoadFileToString(MySchemaJson, *SchemaFilePath))
   {
       UGenAISchemaService::RequestStructuredOutput(
           TEXT("Generate a list of users and their details"),
           MySchemaJson,
           [](const FString& Response, const FString& Error, bool Success) {
              if (Success)
              {
                  UE_LOG(LogTemp, Log, TEXT("Structured Output: %s"), *Response);
              }
              else
              {
                  UE_LOG(LogTemp, Error, TEXT("Error: %s"), *Error);
              }
           }
       );
   }
   ```
## Contribution Guidelines:
### Project Structure:


## References:

* Env Var set logic
  from: [OpenAI-Api-Unreal by KellanM](https://github.com/KellanM/OpenAI-Api-Unreal/blob/main/Source/OpenAIAPI/Private/OpenAIUtils.cpp)